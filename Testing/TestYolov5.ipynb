{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "de9b9a8e2173994f"
  },
  {
   "cell_type": "markdown",
   "id": "efe4467b-c886-4b53-b690-b9ba9771f3ae",
   "metadata": {},
   "source": [
    "# YoloV5 Test\n",
    "## Generate Image Dataset\n",
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddccc9e0-5869-42cc-b21b-547a13f415a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T20:25:01.830533400Z",
     "start_time": "2023-12-19T20:24:58.990032300Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from modules import image_processing as ip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef1b4e9-e37e-4fe4-9819-59f08b1d9a38",
   "metadata": {},
   "source": [
    "### Variable Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3673ab9e-06fa-451e-9f59-43da59a80fe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T20:25:05.371195900Z",
     "start_time": "2023-12-19T20:25:05.363582500Z"
    }
   },
   "outputs": [],
   "source": [
    "img_size= 240\n",
    "\n",
    "img_folder_path = 'C:\\\\Users\\\\doett\\\\Documents\\\\Workspace\\\\GitHub\\\\proj-sorting-robot\\\\Testing\\\\YoloObjektDetection\\\\Images\\\\Dataset\\\\Srews_Nuts_Washers_Overlaps'\n",
    "image_name = '1.jpg'\n",
    "image_path = img_folder_path + '\\\\' + image_name\n",
    "\n",
    "model_weights_path = 'C:\\\\Users\\\\doett\\\\Documents\\\\Workspace\\\\GitHub\\\\proj-sorting-robot\\\\Testing\\\\yolov5_temp\\\\runs\\\\train\\\\Big\\\\weights\\\\best.pt'\n",
    "\n",
    "labels = ['OverlapingObjects', 'Nut', 'Screw', 'Washer']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854872fc6be33115",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load YoloV5-Model pretrained with own data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de083a3ff9e1f43",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:25:18.003171500Z",
     "start_time": "2023-12-19T20:25:11.825066900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doett\\Documents\\Workspace\\GitHub\\proj-sorting-robot\\Testing\\yolov5_temp\\runs\\train\\Big\\weights\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\doett/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-12-17 Python-3.11.5 torch-2.1.2+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 322 layers, 86193601 parameters, 0 gradients, 203.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "def load_model(path):\n",
    "    # Lade das trainierte Modell\n",
    "    print(path)\n",
    "    #model = torch.load(model_weights_path, map_location='cpu')\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'custom', path=path)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = load_model(path=model_weights_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6405023a8767913e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Load Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6db708fe6aaa02a7",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:25:47.919621500Z",
     "start_time": "2023-12-19T20:25:18.004170200Z"
    }
   },
   "outputs": [],
   "source": [
    "image_path =  'C:\\\\Users\\\\doett\\\\Documents\\\\Workspace\\\\GitHub\\\\proj-sorting-robot\\\\Testing\\\\YoloObjektDetection\\\\Images\\\\Dataset\\\\Srews_Nuts_Washers_Overlaps\\\\1.jpg'\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Überprüfen, ob das Bild erfolgreich geladen wurde\n",
    "if image is not None:\n",
    "    cv2.imshow('Image', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"[WARNING] No image loaded\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b1a202-f729-440f-aa37-5e1d79544859",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Load more files of one Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b71d380f-b04f-4e5c-96d4-e62f563d8835",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:54:08.129116200Z",
     "start_time": "2023-12-17T18:54:06.389493100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to load 1.json\n",
      "Unable to load 10.json\n",
      "Unable to load 11.json\n",
      "Unable to load 12.json\n",
      "Unable to load 13.json\n",
      "Unable to load 14.json\n",
      "Unable to load 15.json\n",
      "Unable to load 16.json\n",
      "Unable to load 17.json\n",
      "Unable to load 18.json\n",
      "Unable to load 19.json\n",
      "Unable to load 2.json\n",
      "Unable to load 20.json\n",
      "Unable to load 21.json\n",
      "Unable to load 22.json\n",
      "Unable to load 23.json\n",
      "Unable to load 24.json\n",
      "Unable to load 25.json\n",
      "Unable to load 26.json\n",
      "Unable to load 27.json\n",
      "Unable to load 28.json\n",
      "Unable to load 29.json\n",
      "Unable to load 3.json\n",
      "Unable to load 30.json\n",
      "Unable to load 31.json\n",
      "Unable to load 32.json\n",
      "Unable to load 33.json\n",
      "Unable to load 34.json\n",
      "Unable to load 35.json\n",
      "Unable to load 36.json\n",
      "Unable to load 37.json\n",
      "Unable to load 38.json\n",
      "Unable to load 39.json\n",
      "Unable to load 4.json\n",
      "Unable to load 40.json\n",
      "Unable to load 41.json\n",
      "Unable to load 42.json\n",
      "Unable to load 43.json\n",
      "Unable to load 44.json\n",
      "Unable to load 45.json\n",
      "Unable to load 46.json\n",
      "Unable to load 47.json\n",
      "Unable to load 48.json\n",
      "Unable to load 49.json\n",
      "Unable to load 5.json\n",
      "Unable to load 50.json\n",
      "Unable to load 6.json\n",
      "Unable to load 7.json\n",
      "Unable to load 8.json\n",
      "Unable to load 9.json\n"
     ]
    }
   ],
   "source": [
    "img_folder_path = 'C:\\\\Users\\\\doett\\\\Documents\\\\Workspace\\\\GitHub\\\\proj-sorting-robot\\\\Testing\\\\YoloObjektDetection\\\\Images\\\\Dataset\\\\Srews_Nuts_Washers_Overlaps'\n",
    "img_array = []\n",
    "# Überprüfen, ob der Ordner existiert\n",
    "if os.path.isdir(img_folder_path):\n",
    "    # Durchlaufe alle Dateien im Ordner\n",
    "    for filename in os.listdir(img_folder_path):\n",
    "        # Pfade für jedes Object erstellen\n",
    "        image_path = os.path.join(img_folder_path, filename)\n",
    "\n",
    "        # Überprüfen, ob es sich um eine Datei handelt\n",
    "        if os.path.isfile(image_path):\n",
    "            # Load Image\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            # Überprüfen, ob das Bild erfolgreich geladen wurde\n",
    "            if image is not None:\n",
    "                img_array.append((image, filename))\n",
    "                cv2.imshow('Image', image)\n",
    "            else:\n",
    "                print(f\"Unable to load {filename}\")\n",
    "        else:\n",
    "            print(f\"No File: {filename} \")\n",
    "else:\n",
    "    print(\"Path don't exists\")\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35992c35-234f-4b7a-aa55-f6e8b99fda58",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af8d0dc9-fe2d-4439-8554-80fe24612467",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-17T17:21:11.378659900Z",
     "start_time": "2023-12-17T17:21:09.365564Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.jpg\n",
      "[[[18 20  8]\n",
      "  [19 21  9]\n",
      "  [22 22 10]\n",
      "  ...\n",
      "  [58 37 10]\n",
      "  [52 26  9]\n",
      "  [45 19  3]]\n",
      "\n",
      " [[18 20  8]\n",
      "  [19 21  9]\n",
      "  [22 22 10]\n",
      "  ...\n",
      "  [58 37 10]\n",
      "  [52 26  9]\n",
      "  [45 19  3]]\n",
      "\n",
      " [[18 20  8]\n",
      "  [19 21  9]\n",
      "  [22 22 10]\n",
      "  ...\n",
      "  [58 37 10]\n",
      "  [52 26  9]\n",
      "  [45 19  3]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[15  8 11]\n",
      "  [16  9 12]\n",
      "  [17 10 13]\n",
      "  ...\n",
      "  [ 5 13 12]\n",
      "  [ 5 13 12]\n",
      "  [ 3 14 12]]\n",
      "\n",
      " [[13  6 11]\n",
      "  [14  7 12]\n",
      "  [16  9 14]\n",
      "  ...\n",
      "  [ 6 14 13]\n",
      "  [ 3 14 12]\n",
      "  [ 1 14 12]]\n",
      "\n",
      " [[14  7 12]\n",
      "  [15  8 13]\n",
      "  [17 10 15]\n",
      "  ...\n",
      "  [ 5 16 14]\n",
      "  [ 4 15 13]\n",
      "  [ 1 14 12]]]\n"
     ]
    }
   ],
   "source": [
    "imageNr = 0\n",
    "\n",
    "def get_image(imagenr):\n",
    "    return img_array[imagenr][0]\n",
    "\n",
    "def get_image_name(imagenr):\n",
    "    return img_array[imagenr][1]\n",
    "\n",
    "print(get_image_name(imageNr))\n",
    "print(get_image(imageNr))\n",
    "\n",
    "cv2.imshow('{}'.format(get_image_name(imageNr)), get_image(imageNr))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdd1555b775b13d",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Predict Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doett\\AppData\\Local\\Temp\\ipykernel_8396\\3208511053.py:40: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box_points = np.int0(box_points)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Shape(31, 232, 3)\n",
      "Lengh232\n",
      "Default Shape(33, 161, 3)\n",
      "Lengh161\n",
      "Default Shape(57, 222, 3)\n",
      "Lengh222\n",
      "Default Shape(17, 214, 3)\n",
      "Lengh214\n",
      "Default Shape(28, 137, 3)\n",
      "Lengh137\n",
      "Default Shape(12, 186, 3)\n",
      "Lengh186\n",
      "Default Shape(22, 391, 3)\n",
      "Lengh391\n",
      "Default Shape(40, 163, 3)\n",
      "Lengh163\n",
      "Default Shape(10, 190, 3)\n",
      "Lengh190\n",
      "Default Shape(18, 228, 3)\n",
      "Lengh228\n",
      "Default Shape(30, 172, 3)\n",
      "Lengh172\n",
      "Default Shape(50, 93, 3)\n",
      "Lengh93\n",
      "Default Shape(31, 180, 3)\n",
      "Lengh180\n",
      "Default Shape(30, 100, 3)\n",
      "Lengh100\n",
      "Default Shape(39, 188, 3)\n",
      "Lengh188\n",
      "Default Shape(31, 157, 3)\n",
      "Lengh157\n",
      "Default Shape(30, 159, 3)\n",
      "Lengh159\n",
      "Default Shape(30, 96, 3)\n",
      "Lengh96\n",
      "Default Shape(23, 371, 3)\n",
      "Lengh371\n",
      "Default Shape(22, 236, 3)\n",
      "Lengh236\n",
      "Default Shape(39, 258, 3)\n",
      "Lengh258\n",
      "Default Shape(37, 37, 3)\n",
      "Lengh37\n",
      "Default Shape(42, 43, 3)\n",
      "Lengh43\n",
      "Default Shape(24, 389, 3)\n",
      "Lengh389\n",
      "Default Shape(29, 30, 3)\n",
      "Lengh30\n",
      "Default Shape(30, 30, 3)\n",
      "Lengh30\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(image_path)\n",
    "image = image[175:950, 0:1700]\n",
    "output = image.copy()\n",
    "results = model(image)\n",
    "\n",
    "cropped_boxes = []  # Liste für ausgeschnittene Boxen\n",
    "con_array = []\n",
    "lengh_array = []\n",
    "\n",
    "for box in results.xyxy[0].cpu().numpy():\n",
    "    box = [float(i) for i in box]\n",
    "    xmin, ymin, xmax, ymax, conf, cls = box\n",
    "    \n",
    "    region = image[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
    "    cvt = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.medianBlur(cvt, 13)\n",
    "    \n",
    "    _, otsu_thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "    contours, _ = cv2.findContours(otsu_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Sortiere Konturen nach Fläche\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    \n",
    "    # Nutze nur die größte Kontur\n",
    "    if contours:\n",
    "        contour = contours[0]\n",
    "        #print(f'contour {contour}')\n",
    "\n",
    "        adjusted_contour = contour.copy()\n",
    "        for i, point in enumerate(adjusted_contour):\n",
    "            adjusted_contour[i][0][0] += xmin  # Verschiebe x-Wert um xmin\n",
    "            adjusted_contour[i][0][1] += ymin  # Verschiebe y-Wert um ymin\n",
    "        \n",
    "        con_array.append(adjusted_contour)\n",
    "        \n",
    "        # Berechne das rotierte Rechteck\n",
    "        rect = cv2.minAreaRect(adjusted_contour)\n",
    "        box_points = cv2.boxPoints(rect)\n",
    "        box_points = np.int0(box_points)\n",
    "        \n",
    "        # Draw Red Box arround eatch item\n",
    "        cv2.drawContours(output, [box_points], 0, (0, 0, 255), 2)\n",
    "        \n",
    "    output = cv2.rectangle(output, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 0), 2)\n",
    "    output = cv2.putText(output, labels[int(cls)], (int(xmin), int(ymin) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                         (0, 255, 0), 1, cv2.LINE_AA)    \n",
    "    \n",
    "rectangles = ip.get_rects_from_contours(con_array)\n",
    "\n",
    "bounding_boxes = ip.get_bounding_boxes_from_rectangles(rectangles)\n",
    "\n",
    "object_images = ip.warp_objects_horizontal(image, rectangles, bounding_boxes)\n",
    "    \n",
    "for i,_ in enumerate(object_images):\n",
    "    lengh_array.append(max(object_images[i].shape))\n",
    "\n",
    "'''\n",
    "for i,image in enumerate(object_images):\n",
    "    cv2.imshow('Single Object',object_images[i])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "'''\n",
    "\n",
    "standardized = ip.standardize_images(object_images)\n",
    "\n",
    "'''\n",
    "for i,image in enumerate(standardized):\n",
    "    cv2.imshow('Single Object',img_array[i])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "'''\n",
    "\n",
    "for i, image in enumerate(standardized):\n",
    "    path = 'C:\\\\Users\\\\doett\\\\Documents\\\\Workspace\\\\GitHub\\\\proj-sorting-robot\\\\Testing\\\\Scanned Data\\\\Item{}.png'.format(i)\n",
    "    cv2.imwrite(path, image)\n",
    "    \n",
    "cv2.imshow(\"Predicted Objects\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T21:19:48.930058500Z",
     "start_time": "2023-12-19T21:17:59.135630800Z"
    }
   },
   "id": "f6633dbcc4ad8e08"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c10aa8779c44ee13",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:54:45.035984Z",
     "start_time": "2023-12-19T20:54:39.447742100Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\doett\\AppData\\Local\\Temp\\ipykernel_8396\\3928964719.py:33: DeprecationWarning: `np.int0` is a deprecated alias for `np.intp`.  (Deprecated NumPy 1.24)\n",
      "  box_points = np.int0(box_points)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "box_points [[476 510]\n",
      " [502 492]\n",
      " [631 687]\n",
      " [605 704]]\n",
      "x_coords [476, 502, 631, 605]\n",
      "y_coords [510, 492, 687, 704]\n",
      "box_points [[1145  541]\n",
      " [1221  399]\n",
      " [1251  414]\n",
      " [1175  557]]\n",
      "x_coords [1145, 1221, 1251, 1175]\n",
      "y_coords [541, 399, 414, 557]\n",
      "box_points [[ 886  299]\n",
      " [1010  116]\n",
      " [1057  147]\n",
      " [ 932  331]]\n",
      "x_coords [886, 1010, 1057, 932]\n",
      "y_coords [299, 116, 147, 331]\n",
      "box_points [[750 255]\n",
      " [922 128]\n",
      " [932 141]\n",
      " [760 269]]\n",
      "x_coords [750, 922, 932, 760]\n",
      "y_coords [255, 128, 141, 269]\n",
      "box_points [[355  93]\n",
      " [374  73]\n",
      " [471 169]\n",
      " [451 189]]\n",
      "x_coords [355, 374, 471, 451]\n",
      "y_coords [93, 73, 169, 189]\n",
      "box_points [[320 384]\n",
      " [483 294]\n",
      " [489 305]\n",
      " [326 395]]\n",
      "x_coords [320, 483, 489, 326]\n",
      "y_coords [384, 294, 305, 395]\n",
      "box_points [[682 103]\n",
      " [704 101]\n",
      " [764 486]\n",
      " [741 490]]\n",
      "x_coords [682, 704, 764, 741]\n",
      "y_coords [103, 101, 486, 490]\n",
      "box_points [[797 609]\n",
      " [871 463]\n",
      " [907 481]\n",
      " [833 627]]\n",
      "x_coords [797, 871, 907, 833]\n",
      "y_coords [609, 463, 481, 627]\n",
      "box_points [[587 520]\n",
      " [597 515]\n",
      " [677 688]\n",
      " [667 693]]\n",
      "x_coords [587, 597, 677, 667]\n",
      "y_coords [520, 515, 688, 693]\n",
      "box_points [[234 679]\n",
      " [437 576]\n",
      " [445 591]\n",
      " [242 696]]\n",
      "x_coords [234, 437, 445, 242]\n",
      "y_coords [679, 576, 591, 696]\n",
      "box_points [[ 992  529]\n",
      " [1047  365]\n",
      " [1076  375]\n",
      " [1021  539]]\n",
      "x_coords [992, 1047, 1076, 1021]\n",
      "y_coords [529, 365, 375, 539]\n",
      "box_points [[1243  580]\n",
      " [1327  539]\n",
      " [1349  584]\n",
      " [1265  625]]\n",
      "x_coords [1243, 1327, 1349, 1265]\n",
      "y_coords [580, 539, 584, 625]\n",
      "box_points [[121 125]\n",
      " [144 105]\n",
      " [262 241]\n",
      " [238 261]]\n",
      "x_coords [121, 144, 262, 238]\n",
      "y_coords [125, 105, 241, 261]\n",
      "box_points [[908 544]\n",
      " [935 530]\n",
      " [980 620]\n",
      " [952 633]]\n",
      "x_coords [908, 935, 980, 952]\n",
      "y_coords [544, 530, 620, 633]\n",
      "box_points [[254 206]\n",
      " [442 206]\n",
      " [442 245]\n",
      " [254 245]]\n",
      "x_coords [254, 442, 442, 254]\n",
      "y_coords [206, 206, 245, 245]\n",
      "box_points [[624 508]\n",
      " [674 358]\n",
      " [704 368]\n",
      " [654 518]]\n",
      "x_coords [624, 674, 704, 654]\n",
      "y_coords [508, 358, 368, 518]\n",
      "box_points [[570 227]\n",
      " [600 227]\n",
      " [600 386]\n",
      " [570 386]]\n",
      "x_coords [570, 600, 600, 570]\n",
      "y_coords [227, 227, 386, 386]\n",
      "box_points [[803 310]\n",
      " [833 309]\n",
      " [835 405]\n",
      " [805 406]]\n",
      "x_coords [803, 833, 835, 805]\n",
      "y_coords [310, 309, 405, 406]\n",
      "box_points [[158 487]\n",
      " [525 428]\n",
      " [529 451]\n",
      " [162 510]]\n",
      "x_coords [158, 525, 529, 162]\n",
      "y_coords [487, 428, 451, 510]\n",
      "box_points [[ 74 377]\n",
      " [310 356]\n",
      " [312 378]\n",
      " [ 76 399]]\n",
      "x_coords [74, 310, 312, 76]\n",
      "y_coords [377, 356, 378, 399]\n",
      "box_points [[1138  196]\n",
      " [1140  156]\n",
      " [1398  175]\n",
      " [1395  214]]\n",
      "x_coords [1138, 1140, 1398, 1395]\n",
      "y_coords [196, 156, 175, 214]\n",
      "box_points [[1059  519]\n",
      " [1096  519]\n",
      " [1096  556]\n",
      " [1059  556]]\n",
      "x_coords [1059, 1096, 1096, 1059]\n",
      "y_coords [519, 519, 556, 556]\n",
      "box_points [[886 377]\n",
      " [929 377]\n",
      " [929 419]\n",
      " [886 419]]\n",
      "x_coords [886, 929, 929, 886]\n",
      "y_coords [377, 377, 419, 419]\n",
      "box_points [[1061  295]\n",
      " [1063  271]\n",
      " [1451  304]\n",
      " [1449  328]]\n",
      "x_coords [1061, 1063, 1451, 1449]\n",
      "y_coords [295, 271, 304, 328]\n",
      "box_points [[551 109]\n",
      " [581 109]\n",
      " [581 138]\n",
      " [551 138]]\n",
      "x_coords [551, 581, 581, 551]\n",
      "y_coords [109, 109, 138, 138]\n",
      "box_points [[609 130]\n",
      " [639 130]\n",
      " [639 160]\n",
      " [609 160]]\n",
      "x_coords [609, 639, 639, 609]\n",
      "y_coords [130, 130, 160, 160]\n",
      "cnt: 26\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(image_path)\n",
    "image = image[175:950, 0:1700]\n",
    "output = image.copy()\n",
    "results = model(image)\n",
    "cnt = 0\n",
    "\n",
    "cropped_boxes = []  # Liste für ausgeschnittene Boxen\n",
    "\n",
    "for box in results.xyxy[0].cpu().numpy():\n",
    "    cnt=cnt+1\n",
    "    box = [float(i) for i in box]\n",
    "    xmin, ymin, xmax, ymax, conf, cls = box\n",
    "    \n",
    "    region = image[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
    "    cvt = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)\n",
    "    blur = cv2.medianBlur(cvt, 13)\n",
    "    \n",
    "    _, otsu_thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_OTSU)\n",
    "\n",
    "    contours, _ = cv2.findContours(otsu_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    con_array = []\n",
    "    \n",
    "    # Sortiere Konturen nach Fläche\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    \n",
    "    # Nutze nur die größte Kontur Aus jedem Bereich\n",
    "    if contours:\n",
    "        contour = contours[0]\n",
    "        \n",
    "        # Berechne das rotierte Rechteck\n",
    "        rect = cv2.minAreaRect(contour)\n",
    "        box_points = cv2.boxPoints(rect)\n",
    "        box_points = np.int0(box_points)\n",
    "        \n",
    "        # Offset basierend auf den Box-Koordinaten\n",
    "        box_points[:, 0] += int(xmin)\n",
    "        box_points[:, 1] += int(ymin)\n",
    "        # Zeichnen der Roten Box um die Contur\n",
    "        print(f'box_points {box_points}')\n",
    "        cv2.drawContours(output, [box_points], 0, (0, 0, 255), 2)\n",
    "        \n",
    "        x_coords = [point[0] for point in box_points]\n",
    "        print(f'x_coords {x_coords}')\n",
    "        y_coords = [point[1] for point in box_points]\n",
    "        print(f'y_coords {y_coords}')\n",
    "\n",
    "        # Finde die Begrenzungen des Rechtecks\n",
    "        x_coords_min, x_coords_max = min(x_coords), max(x_coords)\n",
    "        y_coords_min, y_coords_max = min(y_coords), max(y_coords)\n",
    "        height = y_coords_max - y_coords_min\n",
    "        width = x_coords_max - x_coords_min\n",
    "        \n",
    "        # Schneide den Bildausschnitt basierend auf den Begrenzungen aus\n",
    "        cropped_image = image[y_coords_min:y_coords_max, x_coords_min:x_coords_max]\n",
    "        \n",
    "        if height < width:\n",
    "            cropped_boxes.append(cropped_image)\n",
    "        else:\n",
    "            cropped_boxes.append(cv2.rotate(cropped_image, cv2.ROTATE_90_COUNTERCLOCKWISE))\n",
    "   \n",
    "    # Draw Green Rectangles \n",
    "    output = cv2.rectangle(output, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 0), 2)\n",
    "    output = cv2.putText(output, labels[int(cls)], (int(xmin), int(ymin) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                         (0, 255, 0), 1, cv2.LINE_AA)    \n",
    "\n",
    "cv2.imshow('Test34', cropped_boxes[0])\n",
    "print(f'cnt: {cnt}')\n",
    "# Draw Objects on Steady Background\n",
    "black_BG = ip.standardize_images(cropped_boxes)\n",
    "\n",
    "for i, image in enumerate(black_BG):\n",
    "\n",
    "    path = 'C:\\\\Users\\\\doett\\\\Documents\\\\Workspace\\\\GitHub\\\\proj-sorting-robot\\\\Testing\\\\Scanned Data\\\\Part{}.png'.format(i)\n",
    "    cv2.imwrite(path, image)\n",
    "    \n",
    "cv2.imshow(\"Predicted Objects\", output)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "outputs": [],
   "source": [
    "image = cv2.imread(image_path)\n",
    "output = image.copy()\n",
    "results = model(image)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-17T18:43:17.050018800Z",
     "start_time": "2023-12-17T18:43:16.383622500Z"
    }
   },
   "id": "2c7cf3c1f314361d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Extract Conventional"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "20df08e1f40444e4"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "DataFolderPath = 'Testing/Scanned Data'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:29:33.050778600Z",
     "start_time": "2023-12-19T20:29:33.035051400Z"
    }
   },
   "id": "f132829b75a55536"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "image = cv2.imread(image_path)\n",
    "output = image.copy()\n",
    "results = model(image)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:29:35.409870200Z",
     "start_time": "2023-12-19T20:29:34.498670Z"
    }
   },
   "id": "eec976176b60385a"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "preprocessed_image = ip.image_preprocessing(image)\n",
    "cv2.imshow('Test',preprocessed_image)\n",
    "contours, rectangles, bounding_boxes, object_images = ip.get_objects_in_preprocessed_image(preprocessed_image,\n",
    "                                                                                             smaller_image_area=True)\n",
    "black_BG = ip.standardize_images(object_images,224)\n",
    "\n",
    "#cv2.imshow('test',black_BG[0])\n",
    "\n",
    "canvas_image = cv2.drawContours(preprocessed_image, bounding_boxes, -1, (0, 0, 255), 2)\n",
    "cv2.imshow('canvas_image',canvas_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-19T20:29:42.119344200Z",
     "start_time": "2023-12-19T20:29:37.339268500Z"
    }
   },
   "id": "61ef17fc180f770a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9fba66976e5b402c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
