{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [],
   "id": "fc8b2b6419dd506f"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# YoloV5 Test\n",
    "## Generate Image Dataset\n",
    "### Imports"
   ],
   "id": "1763531d21983dff"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T16:26:31.057593200Z",
     "start_time": "2023-12-21T16:26:31.039996Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "from modules import image_processing as ip\n",
    "import json"
   ],
   "id": "b96fdb583dff0594"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Variable Settings"
   ],
   "id": "a801553fc43449dc"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T14:44:24.207817Z",
     "start_time": "2023-12-21T14:44:24.193368400Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "img_size= 240\n",
    "\n",
    "#img_folder_path = 'C:\\\\Users\\\\doett\\\\Documents\\\\Workspace\\\\GitHub\\\\proj-sorting-robot\\\\Testing\\\\YoloObjektDetection\\\\Images\\\\Dataset\\\\Srews_Nuts_Washers_Overlaps'\n",
    "img_folder_path = 'E:\\\\Studierendenprojekte\\\\proj-camera-controller_\\\\Testing\\\\YoloObjektDetection\\\\Images\\\\Dataset\\\\Srews_Nuts_Washers_Overlaps'\n",
    "image_name = '1.jpg'\n",
    "image_path = img_folder_path + '\\\\' + image_name\n",
    "\n",
    "#model_weights_path = 'C:\\\\Users\\\\doett\\\\Documents\\\\Workspace\\\\GitHub\\\\proj-sorting-robot\\\\Testing\\\\yolov5_temp\\\\runs\\\\train\\\\Big\\\\weights\\\\best.pt'\n",
    "model_weights_path = 'E:\\\\Studierendenprojekte\\\\proj-camera-controller_\\\\Testing\\\\yolov5_temp\\\\runs\\\\train\\\\Big\\\\weights\\\\best.pt'\n",
    "\n",
    "labels = ['OverlapingObjects', 'Nut', 'Screw', 'Washer']"
   ],
   "id": "bcdb726445bbabf9"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load YoloV5-Model pretrained with own data"
   ],
   "id": "1e2567ca2cfb3ab7"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T14:44:31.037126Z",
     "start_time": "2023-12-21T14:44:27.202934200Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "E:\\Studierendenprojekte\\proj-camera-controller_\\Testing\\yolov5_temp\\runs\\train\\Big\\weights\\best.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\AI-Student/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-11-17 Python-3.9.12 torch-2.1.2+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 322 layers, 86193601 parameters, 0 gradients, 203.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "def load_model(path):\n",
    "    # Lade das trainierte Modell\n",
    "    print(path)\n",
    "    #model = torch.load(model_weights_path, map_location='cpu')\n",
    "    model = torch.hub.load('ultralytics/yolov5', 'custom', path=path)\n",
    "    return model\n",
    "\n",
    "\n",
    "model = load_model(path=model_weights_path)"
   ],
   "id": "9cb3ed49d62fb044"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load Images"
   ],
   "id": "59cffd3459e55cf5"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T10:12:12.933416200Z",
     "start_time": "2023-12-21T10:12:10.884810100Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_path='E:\\\\Studierendenprojekte\\\\proj-camera-controller_\\\\Testing\\\\YoloObjektDetection\\\\Images\\\\Dataset\\\\Srews_Nuts_Washers_Overlaps\\\\1.jpg'\n",
    "img_folder_path = 'YoloObjektDetection/Images/dataset/Srews_Nuts_Washers_Overlaps/1.jpg'\n",
    "\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Überprüfen, ob das Bild erfolgreich geladen wurde\n",
    "if image is not None:\n",
    "    cv2.imshow('Image', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "else:\n",
    "    print(\"[WARNING] No image loaded\")\n",
    "    "
   ],
   "id": "610372a2a97b476f"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Load more files of one Folder"
   ],
   "id": "ff6fcb9ae4e7e4ce"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2023-12-21T14:46:08.459466400Z",
     "start_time": "2023-12-21T14:46:08.026706Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 24 Images\n"
     ]
    }
   ],
   "source": [
    "img_folder_path = 'YoloObjektDetection/Images/dataset/Dataset_New'\n",
    "img_array = []\n",
    "# Überprüfen, ob der Ordner existiert\n",
    "if os.path.isdir(img_folder_path):\n",
    "    # Durchlaufe alle Dateien im Ordner\n",
    "    for filename in os.listdir(img_folder_path):\n",
    "        # Pfade für jedes Object erstellen\n",
    "        image_path = os.path.join(img_folder_path, filename)\n",
    "\n",
    "        # Überprüfen, ob es sich um eine Datei handelt\n",
    "        if os.path.isfile(image_path):\n",
    "            # Load Image\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            # Überprüfen, ob das Bild erfolgreich geladen wurde\n",
    "            if image is not None:\n",
    "                img_array.append(image)\n",
    "            else:\n",
    "                print(f\"Unable to load {filename}\")\n",
    "        else:\n",
    "            print(f\"No File: {filename} \")\n",
    "else:\n",
    "    print(\"Path don't exists\")\n",
    "\n",
    "print(f'Loaded {len(img_array)} Images')\n"
   ],
   "id": "21e2510a7a7665b9"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [],
   "id": "5335c1861fe56e12"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T13:07:41.227696Z",
     "start_time": "2023-12-21T13:07:41.209625800Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_image(imagenr):\n",
    "    return img_array[imagenr][0]\n",
    "\n",
    "def get_image_name(imagenr):\n",
    "    return img_array[imagenr][1]"
   ],
   "id": "8e515e4dc0aa2190"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Predict Results"
   ],
   "id": "df96c30cb03045ec"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def expand_rotated_box(box_point, offset):\n",
    "    # Finde den Mittelpunkt der Boundingbox\n",
    "    center = np.mean(box_points, axis=0)\n",
    "    \n",
    "    # Berechne die Differenzen der Eckpunkte zum Mittelpunkt\n",
    "    diff = box_points - center\n",
    "    \n",
    "    # Berechne die Winkel der Eckpunkte zur x-Achse\n",
    "    angles = np.arctan2(diff[:, 1], diff[:, 0])\n",
    "    \n",
    "    # Füge den Offset-Wert zu den Radien der Eckpunkte hinzu\n",
    "    radii = np.sqrt(np.sum(diff ** 2, axis=1)) + offset\n",
    "    \n",
    "    # Berechne die neuen Koordinaten der erweiterten Boundingbox\n",
    "    new_x = center[0] + radii * np.cos(angles)\n",
    "    new_y = center[1] + radii * np.sin(angles)\n",
    "    expanded_box = np.column_stack([new_x, new_y]).astype(int)\n",
    "    return expanded_box"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T14:47:11.343786200Z",
     "start_time": "2023-12-21T14:47:11.328305600Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "9edbac5544b4ad6d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-21T14:47:51.787826100Z",
     "start_time": "2023-12-21T14:47:11.821214100Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "length_array = []\n",
    "names_array = []\n",
    "all_objects_array = []\n",
    "all_standardized_array = []\n",
    "object_images = []\n",
    "\n",
    "\n",
    "for img_nr, img in enumerate(img_array):\n",
    "    image = img\n",
    "    image = image[175:950, 0:1700]\n",
    "    output = image.copy()\n",
    "    results = model(image)\n",
    "    con_array = []\n",
    "    \n",
    "    cropped_boxes = []  # Liste für ausgeschnittene Boxen\n",
    "    \n",
    "    for box in results.xyxy[0].cpu().numpy():\n",
    "        box = [float(i) for i in box]\n",
    "        xmin, ymin, xmax, ymax, conf, cls = box\n",
    "        \n",
    "        # Cut the ROI\n",
    "        region = image[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
    "        \n",
    "        # Convert the ROI into greyscale\n",
    "        cvt = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Blur the ROI\n",
    "        blur = cv2.medianBlur(cvt, 9)\n",
    "        # Define threshold by OTSU Method      \n",
    "        otsu_threshold, binary_image = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        \n",
    "        # Anpassen des Schwellenwerts (z. B. um 10 Einheiten erhöhen)\n",
    "        \n",
    "        adjusted_threshold = otsu_threshold + 10\n",
    "        \n",
    "        # Anwenden des angepassten Schwellenwerts\n",
    "        _, otsu_thresh = cv2.threshold(blur, adjusted_threshold, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        # Detect the contours in the yoloV5-area box\n",
    "        contours, _ = cv2.findContours(otsu_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        # Sort the detected contours by size of the area\n",
    "        contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "        \n",
    "        # Use the biggest contur\n",
    "        if contours:\n",
    "            contour = contours[0]\n",
    "        \n",
    "            adjusted_contour = contour.copy()\n",
    "            for i, point in enumerate(adjusted_contour):\n",
    "                adjusted_contour[i][0][0] += xmin  # Verschiebe x-Wert um xmin\n",
    "                adjusted_contour[i][0][1] += ymin  # Verschiebe y-Wert um ymin\n",
    "            \n",
    "            con_array.append(adjusted_contour)\n",
    "            \n",
    "            # Calculate rotated Rectangle\n",
    "            rect = cv2.minAreaRect(adjusted_contour)\n",
    "            box_points = cv2.boxPoints(rect)   \n",
    "            box_points = np.int0(box_points)\n",
    "            \n",
    "            # Der Offset-Wert für die Erweiterung in alle Richtungen (Beispielwert)\n",
    "            expanded_box = expand_rotated_box(box_points, 10)\n",
    "            \n",
    "            # Draw Red Box arround eatch item\n",
    "            cv2.drawContours(output, [box_points], 0, (0, 0, 255), 2)\n",
    "            cv2.drawContours(output, [expanded_box], 0, (255, 0, 0), 2)\n",
    "            \n",
    "        output = cv2.rectangle(output, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 0), 2)\n",
    "        output = cv2.putText(output, labels[int(cls)], (int(xmin), int(ymin) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                             (0, 255, 0), 1, cv2.LINE_AA)    \n",
    "    cv2.imshow(\"Output\", output)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "    rectangles = ip.get_rects_from_contours(con_array)\n",
    "    bounding_boxes = ip.get_bounding_boxes_from_rectangles(rectangles)\n",
    "    \n",
    "    object_images = ip.warp_objects_horizontal(image, rectangles, bounding_boxes)\n",
    "    for obj in object_images:\n",
    "        all_objects_array.append(obj)\n",
    "    \n",
    "standardized = ip.standardize_images(all_objects_array)\n",
    "for standard in standardized:\n",
    "    all_standardized_array.append(standard)\n",
    "\n",
    "for i, image in enumerate(all_standardized_array):\n",
    "    path = 'Scanned Data/Part{}.png'.format(i)\n",
    "    names_array.append('Part{}.png'.format(i))\n",
    "    cv2.imwrite(path, image)\n",
    "\n",
    "\n",
    "for i,_ in enumerate(all_objects_array):\n",
    "    length_array.append(max(all_objects_array[i][0].shape))\n",
    "\n",
    "data = {}\n",
    "for idx, name in enumerate(names_array):\n",
    "    data[name] = length_array[idx]\n",
    "\n",
    "# Schreiben der Daten in eine JSON-Datei\n",
    "with open('Dataset.json', 'w') as file:\n",
    "    json.dump(data, file)\n",
    "        "
   ],
   "id": "6f838c2f034820ea"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "### Load Data from path by Json"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "f20be1c952bba430"
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names of Images:  ['Part0.png', 'Part1.png', 'Part2.png', 'Part3.png', 'Part4.png', 'Part5.png', 'Part6.png', 'Part7.png', 'Part8.png', 'Part9.png', 'Part10.png', 'Part11.png', 'Part12.png', 'Part13.png', 'Part14.png', 'Part15.png', 'Part16.png', 'Part17.png', 'Part18.png', 'Part19.png', 'Part20.png', 'Part21.png', 'Part22.png', 'Part23.png', 'Part24.png', 'Part25.png']\n",
      "Length:  [231, 156, 196, 78, 132, 158, 386, 160, 186, 229, 170, 85, 152, 98, 190, 154, 160, 94, 364, 175, 221, 36, 42, 378, 29, 29]\n",
      "Image Count:  26\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "path_Dataset = 'Scanned Data'\n",
    "path_Json = 'Dataset.json'\n",
    "\n",
    "# List of all Data in Dataset\n",
    "file_names = os.listdir(path_Dataset)\n",
    "\n",
    "# Load Data from Path\n",
    "with open(path_Json, 'r') as file:\n",
    "    loaded_data = json.load(file)\n",
    "\n",
    "# Extract all Names and Length of Images\n",
    "image_names_array = list(loaded_data.keys())  \n",
    "length_array = list(loaded_data.values())    \n",
    "\n",
    "# Load Images with CV2\n",
    "images = []\n",
    "for i in range(len(image_names_array)):\n",
    "    image = cv2.imread(path_Dataset + '\\\\' + image_names_array[i])  \n",
    "\n",
    "    if image is not None:\n",
    "        images.append(image) \n",
    "\n",
    "# Output of Data\n",
    "print(\"Names of Images: \", image_names_array)\n",
    "print(\"Length: \", length_array)\n",
    "print(\"Image Count: \", len(images))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T12:49:10.359079800Z",
     "start_time": "2023-12-21T12:49:10.322117600Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "7993e4df12e5bc2d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Extract Conventional"
   ],
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "aa09cffce5da95b1"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T20:29:33.050778600Z",
     "start_time": "2023-12-19T20:29:33.035051400Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "DataFolderPath = 'Testing/Scanned Data'"
   ],
   "id": "5d64236d6cc68e3e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T20:29:35.409870200Z",
     "start_time": "2023-12-19T20:29:34.498670Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image = cv2.imread(image_path)\n",
    "output = image.copy()\n",
    "results = model(image)"
   ],
   "id": "bfe567f9c16d52b4"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-19T20:29:42.119344200Z",
     "start_time": "2023-12-19T20:29:37.339268500Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "preprocessed_image = ip.image_preprocessing(image)\n",
    "cv2.imshow('Test',preprocessed_image)\n",
    "contours, rectangles, bounding_boxes, object_images = ip.get_objects_in_preprocessed_image(preprocessed_image,\n",
    "                                                                                             smaller_image_area=True)\n",
    "black_BG = ip.standardize_images(object_images,224)\n",
    "\n",
    "#cv2.imshow('test',black_BG[0])\n",
    "\n",
    "canvas_image = cv2.drawContours(preprocessed_image, bounding_boxes, -1, (0, 0, 255), 2)\n",
    "cv2.imshow('canvas_image',canvas_image)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "\n",
    "    "
   ],
   "id": "2e43d6cca3e7aab6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Backup"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "id": "3c618fa0e400795b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "image = cv2.imread(image_path)\n",
    "image = image[175:950, 0:1700]\n",
    "output = image.copy()\n",
    "results = model(image)\n",
    "\n",
    "cropped_boxes = []  # Liste für ausgeschnittene Boxen\n",
    "con_array = []\n",
    "lengh_array = []\n",
    "names_array=[]\n",
    "\n",
    "for box in results.xyxy[0].cpu().numpy():\n",
    "    box = [float(i) for i in box]\n",
    "    xmin, ymin, xmax, ymax, conf, cls = box\n",
    "    \n",
    "    # Cut the ROI\n",
    "    region = image[int(ymin):int(ymax), int(xmin):int(xmax)]\n",
    "    \n",
    "    # Convert the ROI into greyscale\n",
    "    cvt = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Blur the ROI\n",
    "    blur = cv2.medianBlur(cvt, 9)\n",
    "    \n",
    "    # Define threshold by OTSU Method      \n",
    "    otsu_threshold, binary_image = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    # Anpassen des Schwellenwerts (z. B. um 10 Einheiten erhöhen)\n",
    "    adjusted_threshold = otsu_threshold + 30\n",
    "\n",
    "    # Anwenden des angepassten Schwellenwerts\n",
    "    _, otsu_thresh = cv2.threshold(blur, adjusted_threshold, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Detect the contours in the yoloV5-area box\n",
    "    contours, _ = cv2.findContours(otsu_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Sort the detected contours by size of the area\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "    \n",
    "    # Use the biggest contur\n",
    "    if contours:\n",
    "        contour = contours[0]\n",
    "        #print(f'contour {contour}')\n",
    "    \n",
    "        adjusted_contour = contour.copy()\n",
    "        for i, point in enumerate(adjusted_contour):\n",
    "            adjusted_contour[i][0][0] += xmin  # Verschiebe x-Wert um xmin\n",
    "            adjusted_contour[i][0][1] += ymin  # Verschiebe y-Wert um ymin\n",
    "        \n",
    "        con_array.append(adjusted_contour)\n",
    "        \n",
    "        # Calculate rotated Rectangle\n",
    "        rect = cv2.minAreaRect(adjusted_contour)\n",
    "        box_points = cv2.boxPoints(rect)   \n",
    "        box_points = np.int0(box_points)\n",
    "        \n",
    "        \n",
    "        # Der Offset-Wert für die Erweiterung in alle Richtungen (Beispielwert)\n",
    "        expanded_box = expand_rotated_box(box_points, 10)\n",
    "        \n",
    "        #print(f'boxpoibnts: {box_points.dtype, box_points.shape, box_points.size, box_points.ctypes}')\n",
    "        #print(f'expanded_box: {expanded_box.dtype, expanded_box.shape, expanded_box.size, expanded_box.ctypes}')\n",
    "        #box_points = expanded_box\n",
    "        \n",
    "        # Draw Red Box arround eatch item\n",
    "        cv2.drawContours(output, [box_points], 0, (0, 0, 255), 2)\n",
    "        cv2.drawContours(output, [expanded_box], 0, (255, 0, 0), 2)\n",
    "        #cv2.imshow(\"Predicted Objects\", output)\n",
    "        #cv2.waitKey(0)\n",
    "        #cv2.destroyAllWindows()\n",
    "        \n",
    "    output = cv2.rectangle(output, (int(xmin), int(ymin)), (int(xmax), int(ymax)), (0, 255, 0), 2)\n",
    "    output = cv2.putText(output, labels[int(cls)], (int(xmin), int(ymin) - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                         (0, 255, 0), 1, cv2.LINE_AA)    \n",
    "    \n",
    "rectangles = ip.get_rects_from_contours(con_array)\n",
    "\n",
    "bounding_boxes = ip.get_bounding_boxes_from_rectangles(rectangles)\n",
    "\n",
    "object_images = ip.warp_objects_horizontal(image, rectangles, bounding_boxes)\n",
    "    \n",
    "for i,_ in enumerate(object_images):\n",
    "    lengh_array.append(max(object_images[i].shape))\n",
    "\n",
    "'''\n",
    "for i,image in enumerate(object_images):\n",
    "    cv2.imshow('Single Object',object_images[i])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "'''\n",
    "\n",
    "standardized = ip.standardize_images(object_images)\n",
    "\n",
    "'''\n",
    "for i,image in enumerate(standardized):\n",
    "    cv2.imshow('Single Object',img_array[i])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "'''\n",
    "\n",
    "for i, image in enumerate(standardized):\n",
    "    path = 'E:\\\\Studierendenprojekte\\\\proj-camera-controller_\\\\Testing\\\\Scanned Data\\\\Part{}.png'.format(i)\n",
    "    names_array.append('Part{}.png'.format(i))\n",
    "    #path = 'C:\\\\Users\\\\doett\\\\Documents\\\\Workspace\\\\GitHub\\\\proj-sorting-robot\\\\Testing\\\\Scanned Data\\\\Item{}.png'.format(i)\n",
    "    cv2.imwrite(path, image)\n",
    "    #print(f'Image {i} saved')\n",
    "    \n",
    "data = {}\n",
    "for idx, name in enumerate(names_array):\n",
    "    data[name] = lengh_array[idx]\n",
    "    \n",
    "with open('bildlaengen.json', 'w') as file:\n",
    "    json.dump(data, file)\n",
    "\n",
    "# Schreiben der Daten in eine JSON-Datei\n",
    "with open('E:\\\\Studierendenprojekte\\\\proj-camera-controller_\\\\Testing\\\\Dataset.json', 'w') as file:\n",
    "    json.dump(data, file)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "id": "3f64fc2307963788"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}