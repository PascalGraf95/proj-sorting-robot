{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Detect Single File\n",
    "python detect.py --weights .\\runs\\train\\yolov7_Screws4\\weights\\best.pt --conf 0.8 --img-size 640 --source 14.jpg --no-trace\n",
    "\n",
    "python .\\segment\\train.py --data data\\custom.yaml --batch 4 --weights yolov7-seg.pt --cfg models\\segment\\yolov7-seg.yaml --img\n",
    " 640 --hyp data\\hyps\\hyp.scratch-high.yaml --epochs 200 --name Final\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "723ef354b697415d"
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "import modules.image_processing as ip\n",
    "import json\n",
    "\n",
    "FILE = Path('Custom_YoloV7.ipynb').resolve()\n",
    "ROOT = FILE.parents[0]  # YOLOv5 root directory\n",
    "\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.append(str(ROOT))  # add ROOT to PATH\n",
    "   \n",
    "ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative\n",
    "\n",
    "from models.common import DetectMultiBackend\n",
    "from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadStreams\n",
    "from utils.general import (LOGGER, Profile, check_file, check_img_size, check_imshow, check_requirements, colorstr, cv2,\n",
    "                           increment_path, non_max_suppression,scale_segments, print_args, scale_coords, strip_optimizer, xyxy2xywh)\n",
    "from utils.plots import Annotator, colors, save_one_box\n",
    "from utils.segment.general import process_mask, scale_masks, masks2segments\n",
    "from utils.segment.plots import plot_masks\n",
    "from utils.torch_utils import select_device, smart_inference_mode\n",
    "\n",
    "import Sorting_Handler as SH\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T15:38:02.277322100Z",
     "start_time": "2024-01-02T15:38:02.249393200Z"
    }
   },
   "id": "c83062104977d051"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8dce5daf72ba1c4"
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [],
   "source": [
    "model_path = 'runs/train-seg/exp2/weights/best.pt'  \n",
    "source = '../../../Datasets/Testing/YoloV7/V2'  \n",
    "imgsz=(640, 640)  # inference size (height, width)\n",
    "saved_Objects_path='../../../Datasets/Scanned Data/V1'"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T15:38:02.285146500Z",
     "start_time": "2024-01-02T15:38:02.281634300Z"
    }
   },
   "id": "3b96a1a3784e7e00"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Defines"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65c1d279bd7cfb09"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "weights=ROOT / model_path  # model.pt path(s)\n",
    "source=ROOT / source  # file/dir/URL/glob, 0 for webcam\n",
    "data=ROOT / 'data/coco128.yaml'  # dataset.yaml path\n",
    "imgsz=(640, 640)  # inference size (height, width)\n",
    "conf_thres=0.9  # confidence threshold\n",
    "iou_thres=0.2  # NMS IOU threshold\n",
    "max_det=1000  # maximum detections per image\n",
    "device=''  # cuda device, i.e. 0 or 0,1,2,3 or cpu\n",
    "view_img=False  # show results\n",
    "save_txt=False  # save results to *.txt\n",
    "save_conf=False  # save confidences in --save-txt labels\n",
    "save_crop=False  # save cropped prediction boxes\n",
    "nosave=False  # do not save images/videos\n",
    "classes=1  # filter by class: --class 0, or --class 0 2 3\n",
    "agnostic_nms=False  # class-agnostic NMS\n",
    "augment=False  # augmented inference\n",
    "visualize=False  # visualize features\n",
    "update=False  # update all models\n",
    "project=ROOT / 'runs/predict-seg'  # save results to project/name\n",
    "name='exp'  # save results to project/name\n",
    "exist_ok=False  # existing project/name ok, do not increment\n",
    "line_thickness=3  # bounding box thickness (pixels)\n",
    "hide_labels=False  # hide labels\n",
    "hide_conf=False  # hide confidences\n",
    "half=False  # use FP16 half-precision inference\n",
    "dnn=False  # use OpenCV DNN for ONNX inference\n",
    "trk = False"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T15:40:35.853029700Z",
     "start_time": "2024-01-02T15:40:35.845019500Z"
    }
   },
   "id": "7875af5de4590bee"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "source = str(source)\n",
    "is_file = Path(source).suffix[1:] in (IMG_FORMATS + VID_FORMATS)\n",
    "ROI_Path = source + '\\ROI'\n",
    "  "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T15:40:38.088987600Z",
     "start_time": "2024-01-02T15:40:38.082471300Z"
    }
   },
   "id": "f7d80c5fe1e16251"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare Data\n",
    "## Clear or Generate ROI folder"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b58125b311bfe7ae"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "if not os.path.exists(ROI_Path):\n",
    "    os.makedirs(ROI_Path)\n",
    "else:\n",
    "    # Delete all existing Files of ROI\n",
    "    for file in os.listdir(ROI_Path):\n",
    "        file_path = os.path.join(ROI_Path, file)\n",
    "        try:\n",
    "            if os.path.isfile(file_path):\n",
    "                os.unlink(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error while deleting file: {file_path}: {e}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T15:40:39.051247300Z",
     "start_time": "2024-01-02T15:40:39.035279Z"
    }
   },
   "id": "f3aa133cbcf7e76c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cut and Generate ROI"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1278f78a1d1ff34b"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "for filename in os.listdir(source):\n",
    "    if filename.endswith(('.jpg', '.jpeg', '.png')):  \n",
    "        img_path = os.path.join(source, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "            \n",
    "        # Hier kannst du die Größe anpassen, z.B. 200x200 Pixel\n",
    "        ROI = img[175:950, 0:1700]  # Beispiel für Zuschneiden auf 200x200 Pixel\n",
    "            \n",
    "        output_img_path = os.path.join(ROI_Path, filename)\n",
    "        cv2.imwrite(output_img_path, ROI)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T15:40:41.300318Z",
     "start_time": "2024-01-02T15:40:39.981248900Z"
    }
   },
   "id": "18e8582925a8a927"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9562e6a7338747ef"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5  yolov7-segmentation-37-g9c92765 Python-3.11.5 torch-2.1.2+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "yolov7-seg summary: 325 layers, 37847870 parameters, 0 gradients, 141.9 GFLOPs\n"
     ]
    }
   ],
   "source": [
    "device = select_device(device)\n",
    "model = DetectMultiBackend( weights, device=device, dnn=dnn, data=data, fp16=half)\n",
    "stride, names, pt = model.stride, model.names, model.pt\n",
    "imgsz = check_img_size(imgsz, s=stride)  # check image size"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T15:40:42.108510200Z",
     "start_time": "2024-01-02T15:40:41.300318Z"
    }
   },
   "id": "244d901ecc01f72"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "dataset = LoadImages(ROI_Path, img_size=imgsz, stride=stride, auto=pt)\n",
    "bs = 1  # batch_size\n",
    "vid_path, vid_writer = [None] * bs, [None] * bs\n",
    "\n",
    "# Run inference\n",
    "model.warmup(imgsz=(1 if pt else bs, 3, *imgsz))  # warmup\n",
    "seen, windows, dt = 0, [], (Profile(), Profile(), Profile())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T15:40:42.119537300Z",
     "start_time": "2024-01-02T15:40:42.112512100Z"
    }
   },
   "id": "4cca54b4628c0263"
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 26 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "28 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 8 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "9 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 12 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "14 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 16 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "13 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 17 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "15 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 18 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "19 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 19 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "16 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 20 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "21 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 20 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "21 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 24 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "24 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 26 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "25 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 26 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "27 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 28 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "29 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 4 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "4 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 5 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "7 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 5 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "7 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 32 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "29 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 32 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "29 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 33 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "28 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 18 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "19 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 23 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "26 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 26 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "27 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 32 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "29 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 32 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "29 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 32 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "29 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 32 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "31 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 25 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "25 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 23 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "23 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 23 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "23 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 23 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "23 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 23 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "23 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 20 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "21 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 23 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "23 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 23 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "23 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 16 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "16 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 11 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "19 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 11 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "10 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 11 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "10 Contours found\n",
      "(775, 1600, 3)\n",
      "Prediction in 1 Image\n",
      "Detected 8 Objects\n",
      "binary_borders_scaled shape : (775, 1600, 3)\n",
      "9 Contours found\n"
     ]
    }
   ],
   "source": [
    "img_nr = 0\n",
    "length_array = []\n",
    "names_array = []\n",
    "\n",
    "for path, im, im0s, vid_cap, s in dataset:\n",
    "    \n",
    "    original = im0s\n",
    "\n",
    "    print(original.shape)\n",
    "    with dt[0]:\n",
    "        im = torch.from_numpy(im).to(device)\n",
    "        im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32\n",
    "        im /= 255  # 0 - 255 to 0.0 - 1.0\n",
    "        if len(im.shape) == 3:\n",
    "            im = im[None]  # expand for batch dim\n",
    "\n",
    "    # Inference\n",
    "    with dt[1]:\n",
    "        #visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False\n",
    "        pred, out = model(im, augment=augment, visualize=visualize)\n",
    "        proto = out[1]\n",
    "\n",
    "    # NMS\n",
    "    with dt[2]:\n",
    "        pred = non_max_suppression(pred, 0.2, iou_thres, classes, agnostic_nms, max_det=max_det, nm=32)\n",
    "\n",
    "    # Second-stage classifier (optional)\n",
    "    # pred = utils.general.apply_classifier(pred, classifier_model, im, im0s)\n",
    "    print(f'Prediction in {len(pred)} Image')\n",
    "    # Process predictions\n",
    "    for i, det in enumerate(pred):  # per image\n",
    "        print(f'Detected {len(det)} Objects')\n",
    "        seen += 1\n",
    "\n",
    "        p, im0, frame = path, im0s.copy(), getattr(dataset, 'frame', 0)\n",
    "\n",
    "        p = Path(p)  # to Path\n",
    "        #save_path = str(save_dir / p.name)  # im.jpg\n",
    "        #txt_path = str(save_dir / 'labels' / p.stem) + ('' if dataset.mode == 'image' else f'_{frame}')  # im.txt\n",
    "        s += '%gx%g ' % im.shape[2:]  # print string\n",
    "        gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh\n",
    "        imc = im0.copy() if save_crop else im0  # for save_crop\n",
    "        annotator = Annotator(im0, line_width=line_thickness, example=str(names))\n",
    "        if len(det):\n",
    "            masks = process_mask(proto[i], det[:, 6:], det[:, :4], im.shape[2:], upsample=True)  # HWC\n",
    "\n",
    "            # Rescale boxes from img_size to im0 size\n",
    "            det[:, :4] = scale_coords(im.shape[2:], det[:, :4], im0.shape).round()\n",
    "\n",
    "            # Segments\n",
    "            if save_txt:\n",
    "                segments = reversed(masks2segments(masks))\n",
    "                segments = [scale_segments(im.shape[2:], x, im0.shape).round() for x in segments]\n",
    "            \n",
    "            # Print results\n",
    "            for c in det[:, 5].unique():\n",
    "                n = (det[:, 5] == c).sum()  # detections per class\n",
    "                s += f\"{n} {names[int(c)]}{'s' * (n > 1)}, \"  # add to string\n",
    "\n",
    "            # Mask plotting ----------------------------------------------------------------------------------------\n",
    "            mcolors = [colors(int(cls), True) for cls in det[:, 5]]\n",
    "            im_masks = plot_masks(im[i], masks, mcolors)  # image with masks shape(imh,imw,3)\n",
    "            \n",
    "            object_coordinates = SH.get_object_coordinates_from_mask(masks)\n",
    "            binary_borders = SH.gen_image(object_coordinates, showImage = False)             \n",
    "            binary_borders_scaled = scale_masks(im.shape[2:], binary_borders, im0.shape)\n",
    "            print(f'binary_borders_scaled shape : {binary_borders_scaled.shape}')\n",
    "            #cv2.imshow('Binary Image (Scaled)', binary_borders_scaled)\n",
    "            #cv2.waitKey(0)\n",
    "            \n",
    "            # Detect the contours in the Threshold Mask \n",
    "            contours, hierarchy = cv2.findContours(image=binary_borders_scaled[:,:,0], mode=cv2.RETR_TREE, method=cv2.CHAIN_APPROX_NONE)\n",
    "            print(f'{len(contours)} Contours found')\n",
    "            \n",
    "             # Mask plotting ----------------------------------------------------------------------------------------\n",
    "            annotator.im = scale_masks(im.shape[2:], im_masks, im0.shape)  # scale to original h, w\n",
    "            # Mask plotting ----------------------------------------------------------------------------------------\n",
    "\n",
    "           \n",
    "            # Write results\n",
    "            for j, (*xyxy, conf, cls) in enumerate(reversed(det[:, :6])):\n",
    "                if save_txt:  # Write to file\n",
    "                    segj = segments[j].reshape(-1)  # (n,2) to (n*2)\n",
    "                    line = (cls, *segj, conf) if save_conf else (cls, *segj)  # label format\n",
    "\n",
    "                if save_crop:\n",
    "                    #save_one_box(xyxy, imc, file=save_dir / 'crops' / names[c] / f'{p.stem}.jpg', BGR=True)\n",
    "                    pass\n",
    "                \n",
    "        # Stream results\n",
    "        im0 = annotator.result()\n",
    "        \n",
    "        showContours = False\n",
    "        if showContours:\n",
    "            cv2.drawContours(im0, contours, -1, (0, 255, 0), 2)\n",
    "            cv2.imshow(str(p), im0)\n",
    "            cv2.waitKey(0)  # 1 millisecond\n",
    "            cv2.destroyAllWindows()\n",
    "        \n",
    "   \n",
    "    rectangles = ip.get_rects_from_contours(contours)\n",
    "    bounding_boxes = ip.get_bounding_boxes_from_rectangles(rectangles)\n",
    "    object_images = ip.warp_objects_horizontal(original, rectangles, bounding_boxes)\n",
    "        \n",
    "    standardized = ip.standardize_images(object_images)  \n",
    "    \n",
    "    # Generate array with the length of the Objects\n",
    "    for i,_ in enumerate(object_images):\n",
    "        length_array.append(max(object_images[i].shape))\n",
    "        \n",
    "    # Save Objet to Folder\n",
    "    for _, image in enumerate(standardized):\n",
    "        img_nr = img_nr+1\n",
    "        name = 'Item{}.png'.format(img_nr)\n",
    "        path = saved_Objects_path +'/'+name\n",
    "        names_array.append(name)\n",
    "        cv2.imwrite(path, image)\n",
    "        \n",
    "    \n",
    "for i,_ in enumerate(object_images):\n",
    "    length_array.append(max(object_images[i][0].shape))\n",
    "\n",
    "data = {}\n",
    "for idx, name in enumerate(names_array):\n",
    "    data[name] = length_array[idx]\n",
    "\n",
    "# Schreiben der Daten in eine JSON-Datei\n",
    "with open(os.path.join(saved_Objects_path, 'Dataset.json'), 'w') as file:\n",
    "    json.dump(data, file)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-02T15:40:51.336974900Z",
     "start_time": "2024-01-02T15:40:42.133535800Z"
    }
   },
   "id": "37b6cb5a0fea467d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-02T15:38:14.364216500Z"
    }
   },
   "id": "d7a61ae79cd2e64d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
